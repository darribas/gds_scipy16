
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <title>Spatial clustering Â· Geographic Data Science with PySAL and the pydata stack</title>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.1.1">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="08_spatial_regression.html" />
    
    
    <link rel="prev" href="06_points.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../distribution.html">
            
                <a href="../distribution.html">
            
                    
                    Distribution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../content/about.html">
            
                <a href="../content/about.html">
            
                    
                    About the authors
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../content/infrastructure/">
            
                <a href="../content/infrastructure/">
            
                    
                    Install guide
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../content/outline.html">
            
                <a href="../content/outline.html">
            
                    
                    Outline
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../content/data/">
            
                <a href="../content/data/">
            
                    
                    Data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../content/part1/">
            
                <a href="../content/part1/">
            
                    
                    Part I
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="01_data_processing.html">
            
                <a href="01_data_processing.html">
            
                    
                    Spatial data processing with PySAL
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="02_geovisualization.html">
            
                <a href="02_geovisualization.html">
            
                    
                    Geovisualization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="03_spatial_weights.html">
            
                <a href="03_spatial_weights.html">
            
                    
                    Spatial weights in PySAL
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="04_esda.html">
            
                <a href="04_esda.html">
            
                    
                    ESDA with PySAL
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="05_spatial_dynamics.html">
            
                <a href="05_spatial_dynamics.html">
            
                    
                    Space-time analysis
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../content/part2/">
            
                <a href="../content/part2/">
            
                    
                    Part II
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="06_points.html">
            
                <a href="06_points.html">
            
                    
                    Points
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.8.2" data-path="07_spatial_clustering.html">
            
                <a href="07_spatial_clustering.html">
            
                    
                    Spatial clustering
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="08_spatial_regression.html">
            
                <a href="08_spatial_regression.html">
            
                    
                    Spatial Regression
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../content/infrastructure/workflow.html">
            
                <a href="../content/infrastructure/workflow.html">
            
                    
                    Development notes
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Spatial clustering</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="spatial-clustering">Spatial Clustering</h1>
<blockquote>
<p><a href="../content/part2/07_spatial_clustering.ipynb"><code>IPYNB</code></a></p>
<p><strong>NOTE</strong>: much of this material has been ported and adapted from &quot;Lab 8&quot; in <a href="http://darribas.org/gds15" target="_blank">Arribas-Bel (2016)</a>.</p>
</blockquote>
<p>This notebook covers a brief introduction to spatial regression. To demonstrate this, we will use a dataset of all the AirBnb listings in the city of Austin (check the Data section for more information about the dataset).</p>
<p>Many questions and topics are complex phenomena that involve several dimensions and are hard to summarize into a single variable. In statistical terms, we call this family of problems <em>multivariate</em>, as oposed to <em>univariate</em> cases where only a single variable is considered in the analysis. Clustering tackles this kind of questions by reducing their dimensionality -the number of relevant variables the analyst needs to look at- and converting it into a more intuitive set of classes that even non-technical audiences can look at and make sense of. For this reason, it is widely use in applied contexts such as policymaking or marketing. In addition, since these methods do not require many preliminar assumptions about the structure of the data, it is a commonly used exploratory tool, as it can quickly give clues about the shape, form and content of a dataset.</p>
<p>The core idea of statistical clustering is to summarize the information contained in several variables by creating a relatively small number of categories. Each observation in the dataset is then assigned to one, and only one, category depending on its values for the variables originally considered in the classification. If done correctly, the exercise reduces the complexity of a multi-dimensional problem while retaining all the meaningful information contained in the original dataset. This is because, once classified, the analyst only needs to look at in which category every observation falls into, instead of considering the multiple values associated with each of the variables and trying to figure out how to put them together in a coherent sense. When the clustering is performed on observations that represent areas, the technique is often called geodemographic analysis.</p>
<p>The basic premise of the exercises we will be doing in this notebook is that, through the characteristics of the houses listed in AirBnb, we can learn about the geography of Austin. In particular, we will try to classify the city&apos;s zipcodes into a small number of groups that will allow us to extract some patterns about the main kinds of houses and areas in the city.</p>
<h2 id="data">Data</h2>
<p>Before anything, let us load up the libraries we will use:</p>
<pre><code class="lang-python">%matplotlib inline

<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> pysal <span class="hljs-keyword">as</span> ps
<span class="hljs-keyword">import</span> geopandas <span class="hljs-keyword">as</span> gpd
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> cluster
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> scale

sns.set(style=<span class="hljs-string">&quot;whitegrid&quot;</span>)
</code></pre>
<p>Let us also set the paths to all the files we will need throughout the tutorial:</p>
<pre><code class="lang-python"><span class="hljs-comment"># Adjust this to point to the right file in your computer</span>
abb_link = <span class="hljs-string">&apos;../data/listings.csv.gz&apos;</span>
zc_link = <span class="hljs-string">&apos;../data/Zipcodes.geojson&apos;</span>
</code></pre>
<p>Before anything, let us load the main dataset:</p>
<pre><code class="lang-python">lst = pd.read_csv(abb_link)
</code></pre>
<p>Originally, this is provided at the individual level. Since we will be working in terms of neighborhoods and areas, we will need to aggregate them to that level. For this illustration, we will be using the following subset of variables:</p>
<pre><code class="lang-python">varis = [<span class="hljs-string">&apos;bedrooms&apos;</span>, <span class="hljs-string">&apos;bathrooms&apos;</span>, <span class="hljs-string">&apos;beds&apos;</span>]
</code></pre>
<p>This will allow us to capture the main elements that describe the &quot;look and feel&quot; of a property and, by aggregation, of an area or neighborhood. All of the variables above are numerical values, so a sensible way to aggregate them is by obtaining the average (of bedrooms, etc.) per zipcode.</p>
<pre><code class="lang-python">aves = lst.groupby(<span class="hljs-string">&apos;zipcode&apos;</span>)[varis].mean()
aves.info()
</code></pre>
<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
Float64Index: 47 entries, 33558.0 to 78759.0
Data columns (total 3 columns):
bedrooms     47 non-null float64
bathrooms    47 non-null float64
beds         47 non-null float64
dtypes: float64(3)
memory usage: 1.5 KB
</code></pre><p>In addition to these variables, it would be good to include also a sense of what proportions of different types of houses each zipcode has. For example, one can imagine that neighborhoods with a higher proportion of condos than single-family homes will probably look and feel more urban. To do this, we need to do some data munging:</p>
<pre><code class="lang-python">types = pd.get_dummies(lst[<span class="hljs-string">&apos;property_type&apos;</span>])
prop_types = types.join(lst[<span class="hljs-string">&apos;zipcode&apos;</span>])\
                  .groupby(<span class="hljs-string">&apos;zipcode&apos;</span>)\
                  .sum()
prop_types_pct = (prop_types * <span class="hljs-number">100.</span>).div(prop_types.sum(axis=<span class="hljs-number">1</span>), axis=<span class="hljs-number">0</span>)
prop_types_pct.info()
</code></pre>
<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
Float64Index: 47 entries, 33558.0 to 78759.0
Data columns (total 18 columns):
Apartment          47 non-null float64
Bed &amp; Breakfast    47 non-null float64
Boat               47 non-null float64
Bungalow           47 non-null float64
Cabin              47 non-null float64
Camper/RV          47 non-null float64
Chalet             47 non-null float64
Condominium        47 non-null float64
Earth House        47 non-null float64
House              47 non-null float64
Hut                47 non-null float64
Loft               47 non-null float64
Other              47 non-null float64
Tent               47 non-null float64
Tipi               47 non-null float64
Townhouse          47 non-null float64
Treehouse          47 non-null float64
Villa              47 non-null float64
dtypes: float64(18)
memory usage: 7.0 KB
</code></pre><p>Now we bring both sets of variables together:</p>
<pre><code class="lang-python">aves_props = aves.join(prop_types_pct)
</code></pre>
<p>And since we will be feeding this into the clustering algorithm, we will first standardize the columns:</p>
<pre><code class="lang-python">db = pd.DataFrame(\
                 scale(aves_props), \
                 index=aves_props.index, \
                 columns=aves_props.columns)\
       .rename(<span class="hljs-keyword">lambda</span> x: str(int(x)))
</code></pre>
<p>Now let us bring geography in:</p>
<pre><code class="lang-python">zc = gpd.read_file(zc_link)
zc.plot(color=<span class="hljs-string">&apos;red&apos;</span>);
</code></pre>
<p><img src="07_spatial_clustering_files/07_spatial_clustering_18_0.png" alt="png"></p>
<p>And combine the two:</p>
<pre><code class="lang-python">zdb = zc[[<span class="hljs-string">&apos;geometry&apos;</span>, <span class="hljs-string">&apos;zipcode&apos;</span>, <span class="hljs-string">&apos;name&apos;</span>]].join(db, on=<span class="hljs-string">&apos;zipcode&apos;</span>)\
                                         .dropna()
</code></pre>
<p>To get a sense of which areas we have lost:</p>
<pre><code class="lang-python">f, ax = plt.subplots(<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">9</span>, <span class="hljs-number">9</span>))

zc.plot(color=<span class="hljs-string">&apos;grey&apos;</span>, linewidth=<span class="hljs-number">0</span>, ax=ax)
zdb.plot(color=<span class="hljs-string">&apos;red&apos;</span>, linewidth=<span class="hljs-number">0.1</span>, ax=ax)

ax.set_axis_off()

plt.show()
</code></pre>
<p><img src="07_spatial_clustering_files/07_spatial_clustering_22_0.png" alt="png"></p>
<h2 id="geodemographic-analysis">Geodemographic analysis</h2>
<p>The main intuition behind geodemographic analysis is to group disparate areas of a city or region into a small set of classes that capture several characteristics shared by those in the same group. By doing this, we can get a new perspective not only on the types of areas in a city, but on how they are distributed over space. In the context of our AirBnb data analysis, the idea is that we can group different zipcodes of Austin based on the type of houses listed on the website. This will give us a hint into the geography of AirBnb in the Texan tech capital.</p>
<p>Although there exist many techniques to statistically group observations in a dataset, all of them are based on the premise of using a set of attributes to define classes or categories of observations that are similar <em>within</em> each of them, but differ <em>between</em> groups. How similarity within groups and dissimilarity between them is defined and how the classification algorithm is operationalized is what makes techniques differ and also what makes each of them particularly well suited for specific problems or types of data. As an illustration, we will only dip our toes into one of these methods, K-means, which is probably the most commonly used technique for statistical clustering.</p>
<p>Technically speaking, we describe the method and the parameters on the following line of code, where we specifically ask for five groups:</p>
<pre><code class="lang-python">cluster.KMeans?
</code></pre>
<pre><code class="lang-python">km5 = cluster.KMeans(n_clusters=<span class="hljs-number">5</span>)
</code></pre>
<p>Following the <code>sklearn</code> pipeline approach, all the heavy-lifting of the clustering happens when we <code>fit</code> the model to the data:</p>
<pre><code class="lang-python">km5cls = km5.fit(zdb.drop([<span class="hljs-string">&apos;geometry&apos;</span>, <span class="hljs-string">&apos;name&apos;</span>], axis=<span class="hljs-number">1</span>).values)
</code></pre>
<p>Now we can extract the classes and put them on a map:</p>
<pre><code class="lang-python">f, ax = plt.subplots(<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">9</span>, <span class="hljs-number">9</span>))

zdb.assign(cl=km5cls.labels_)\
   .plot(column=<span class="hljs-string">&apos;cl&apos;</span>, categorical=<span class="hljs-keyword">True</span>, legend=<span class="hljs-keyword">True</span>, \
         linewidth=<span class="hljs-number">0.1</span>, edgecolor=<span class="hljs-string">&apos;white&apos;</span>, ax=ax)

ax.set_axis_off()

plt.show()
</code></pre>
<p><img src="07_spatial_clustering_files/07_spatial_clustering_29_0.png" alt="png"></p>
<p>The map above shows a clear pattern: there is a class at the core of the city (number 0, in red), then two other ones in a sort of &quot;urban ring&quot; (number 1 and 3, in green and brown, respectively), and two peripheral sets of areas (number 2 and 4, yellow and green).</p>
<p>This gives us a good insight into the geographical structure, but does not tell us much about what are the defining elements of these groups. To do that, we can have a peak into the characteristics of the classes. For example, let us look at how the proportion of different types of properties are distributed across clusters:</p>
<pre><code class="lang-python">cl_pcts = prop_types_pct.rename(<span class="hljs-keyword">lambda</span> x: str(int(x)))\
                          .reindex(zdb[<span class="hljs-string">&apos;zipcode&apos;</span>])\
                          .assign(cl=km5cls.labels_)\
                          .groupby(<span class="hljs-string">&apos;cl&apos;</span>)\
                          .mean()
</code></pre>
<pre><code class="lang-python">f, ax = plt.subplots(<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">18</span>, <span class="hljs-number">9</span>))
cl_pcts.plot(kind=<span class="hljs-string">&apos;barh&apos;</span>, stacked=<span class="hljs-keyword">True</span>, ax=ax, \
             cmap=<span class="hljs-string">&apos;Set2&apos;</span>, linewidth=<span class="hljs-number">0</span>)
ax.legend(ncol=<span class="hljs-number">1</span>, loc=<span class="hljs-string">&quot;right&quot;</span>);
</code></pre>
<p><img src="07_spatial_clustering_files/07_spatial_clustering_32_0.png" alt="png"></p>
<p>A few interesting, albeit maybe not completely unsurprising, characteristics stand out. First, most of the locations we have in the dataset are either apartments or houses. However, how they are distributed is interesting. The urban core -cluster 0- distinctively has the highest proportion of condos and lofts. The suburban ring -clusters 1 and 3- is very consistent, with a large share of houses and less apartments, particularly so in the case of cluster 3. Class 4 has only two types of properties, houses and apartments, suggesting there are not that many places listed at AirBnb. Finally, class 3 arises as a more rural and leisure one: beyond apartments, it has a large share of bed &amp; breakfasts.</p>
<p><strong>Mini Exercise</strong></p>
<blockquote>
<p><em>What are the average number of beds, bedrooms and bathrooms for every class?</em></p>
</blockquote>
<h2 id="regionalization-analysis-building-meaningful-regions">Regionalization analysis: building (meaningful) regions</h2>
<p>In the case of analysing spatial data, there is a subset of methods that are of particular interest for many common cases in Geographic Data Science. These are the so-called regionalization techniques. Regionalization methods can take also many forms and faces but, at their core, they all involve statistical clustering of observations with the additional constraint that observations need to be geographical neighbors to be in the same category. Because of this, rather than category, we will use the term area for each observation and region for each class or cluster -hence regionalization, the construction of regions from smaller areas.</p>
<p>As in the non-spatial case, there are many different algorithms to perform regionalization, and they all differ on details relating to the way they measure (dis)similarity, the process to regionalize, etc. However, same as above too, they all share a few common aspects. In particular, they all take a set of input attributes <em>and</em> a representation of space in the form of a binary spatial weights matrix. Depending on the algorithm, they also require the desired number of output regions into which the areas are aggregated.</p>
<p>In this example, we are going to create aggregations of zipcodes into groups that have areas where the AirBnb listed location have similar ratings. In other words, we will create delineations for the &quot;quality&quot; or &quot;satisfaction&quot; of AirBnb users. In other words, we will explore what are the boundaries that separate areas where AirBnb users tend to be satisfied about their experience versus those where the ratings are not as high. To do this, we will focus on the <code>review_scores_X</code> set of variables in the original dataset:</p>
<pre><code class="lang-python">ratings = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> lst <span class="hljs-keyword">if</span> <span class="hljs-string">&apos;review_scores_&apos;</span> <span class="hljs-keyword">in</span> i]
ratings
</code></pre>
<pre><code>[&apos;review_scores_rating&apos;,
 &apos;review_scores_accuracy&apos;,
 &apos;review_scores_cleanliness&apos;,
 &apos;review_scores_checkin&apos;,
 &apos;review_scores_communication&apos;,
 &apos;review_scores_location&apos;,
 &apos;review_scores_value&apos;]
</code></pre><p>Similarly to the case above, we now bring this at the zipcode level. Note that, since they are all scores that range from 0 to 100, we can use averages and we do not need to standardize.</p>
<pre><code class="lang-python">rt_av = lst.groupby(<span class="hljs-string">&apos;zipcode&apos;</span>)[ratings]\
           .mean()\
           .rename(<span class="hljs-keyword">lambda</span> x: str(int(x)))
</code></pre>
<p>And we link these to the geometries of zipcodes:</p>
<pre><code class="lang-python">zrt = zc[[<span class="hljs-string">&apos;geometry&apos;</span>, <span class="hljs-string">&apos;zipcode&apos;</span>]].join(rt_av, on=<span class="hljs-string">&apos;zipcode&apos;</span>)\
                                 .dropna()
zrt.info()
</code></pre>
<pre><code>&lt;class &apos;geopandas.geodataframe.GeoDataFrame&apos;&gt;
Int64Index: 43 entries, 0 to 78
Data columns (total 9 columns):
geometry                       43 non-null object
zipcode                        43 non-null object
review_scores_rating           43 non-null float64
review_scores_accuracy         43 non-null float64
review_scores_cleanliness      43 non-null float64
review_scores_checkin          43 non-null float64
review_scores_communication    43 non-null float64
review_scores_location         43 non-null float64
review_scores_value            43 non-null float64
dtypes: float64(7), object(2)
memory usage: 3.4+ KB
</code></pre><p>In contrast to the standard clustering techniques, regionalization requires a formal representation of topology. This is so the algorithm can impose spatial constraints during the process of clustering the observations. We will use exactly the same approach as in the previous sections of this tutorial for this and build spatial weights objects <code>W</code> with <code>PySAL</code>. For the sake of this illustration, we will consider queen contiguity, but any other rule should work fine as long as there is a rational behind it. Weights constructors currently only work from shapefiles on disk, so we will write our <code>GeoDataFrame</code> first, then create the <code>W</code> object, and remove the files.</p>
<pre><code class="lang-python">zrt.to_file(<span class="hljs-string">&apos;tmp&apos;</span>)
w = ps.queen_from_shapefile(<span class="hljs-string">&apos;tmp/tmp.shp&apos;</span>, idVariable=<span class="hljs-string">&apos;zipcode&apos;</span>)
<span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> this might not work on Windows</span>
! rm -r tmp
w
</code></pre>
<pre><code>&lt;pysal.weights.weights.W at 0x11bd5ff98&gt;
</code></pre><p>Now we are ready to run the regionalization algorithm. In this case we will use the <code>max-p</code> (<a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9787.2011.00743.x/abstract" target="_blank">Duque, Anselin &amp; Rey, 2012)</a>, which does not require a predefined number of output regions but instead it takes a target variable that you want to make sure a minimum threshold is met. In our case, since it is based on ratings, we will impose that every resulting region has at least 10% of the total number of reviews. Let us work through what that would mean:</p>
<pre><code class="lang-python">n_rev = lst.groupby(<span class="hljs-string">&apos;zipcode&apos;</span>)\
           .sum()\
           [<span class="hljs-string">&apos;number_of_reviews&apos;</span>]\
           .rename(<span class="hljs-keyword">lambda</span> x: str(int(x)))\
           .reindex(zrt[<span class="hljs-string">&apos;zipcode&apos;</span>])
thr = np.round(<span class="hljs-number">0.1</span> * n_rev.sum())
thr
</code></pre>
<pre><code>6271.0
</code></pre><p>This means we want every resulting region to be based on at least 6,271 reviews. Now we have all the pieces, let us glue them together through the algorithm:</p>
<pre><code class="lang-python"><span class="hljs-comment"># Set the seed for reproducibility</span>
np.random.seed(<span class="hljs-number">1234</span>)

z = zrt.drop([<span class="hljs-string">&apos;geometry&apos;</span>, <span class="hljs-string">&apos;zipcode&apos;</span>], axis=<span class="hljs-number">1</span>).values
maxp = ps.region.Maxp(w, z, thr, n_rev.values[:, <span class="hljs-keyword">None</span>], initial=<span class="hljs-number">1000</span>)
</code></pre>
<p>We can check whether the solution is better (lower within sum of squares) than we would have gotten from a purely random regionalization process using the <a href="http://pysal.readthedocs.io/en/latest/library/region/maxp.html#pysal.region.maxp.Maxp.cinference" target="_blank"><code>cinference</code></a> method:</p>
<pre><code class="lang-python">%%time
np.random.seed(<span class="hljs-number">1234</span>)
maxp.cinference(nperm=<span class="hljs-number">999</span>)
</code></pre>
<pre><code>CPU times: user 26.2 s, sys: 185 ms, total: 26.4 s
Wall time: 32.1 s
</code></pre><p>Which allows us to obtain an empirical p-value:</p>
<pre><code class="lang-python">maxp.cpvalue
</code></pre>
<pre><code>0.022
</code></pre><p>Which gives us reasonably good confidence that the solution we obtain is more meaningful than pure chance. </p>
<p>With that out of the way, let us see what the result looks like on a map! First we extract the labels:</p>
<pre><code class="lang-python">lbls = pd.Series(maxp.area2region).reindex(zrt[<span class="hljs-string">&apos;zipcode&apos;</span>])
</code></pre>
<pre><code class="lang-python">f, ax = plt.subplots(<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">9</span>, <span class="hljs-number">9</span>))

zrt.assign(cl=lbls.values)\
   .plot(column=<span class="hljs-string">&apos;cl&apos;</span>, categorical=<span class="hljs-keyword">True</span>, legend=<span class="hljs-keyword">True</span>, \
         linewidth=<span class="hljs-number">0.1</span>, edgecolor=<span class="hljs-string">&apos;white&apos;</span>, ax=ax)

ax.set_axis_off()

plt.show()
</code></pre>
<p><img src="07_spatial_clustering_files/07_spatial_clustering_52_0.png" alt="png"></p>
<p>The map shows a clear geographical pattern with a western area, another in the North and a smaller one in the East. Let us unpack what each of them is made of:</p>
<pre><code class="lang-python">zrt[ratings].groupby(lbls.values).mean().T
</code></pre>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>review_scores_rating</th>
      <td>96.911817</td>
      <td>95.326614</td>
      <td>92.502135</td>
      <td>96.174762</td>
      <td>94.418213</td>
    </tr>
    <tr>
      <th>review_scores_accuracy</th>
      <td>9.767500</td>
      <td>9.605032</td>
      <td>9.548751</td>
      <td>9.607459</td>
      <td>9.566245</td>
    </tr>
    <tr>
      <th>review_scores_cleanliness</th>
      <td>9.678277</td>
      <td>9.558179</td>
      <td>8.985408</td>
      <td>9.599824</td>
      <td>9.520539</td>
    </tr>
    <tr>
      <th>review_scores_checkin</th>
      <td>9.922450</td>
      <td>9.797086</td>
      <td>9.765563</td>
      <td>9.889927</td>
      <td>9.754648</td>
    </tr>
    <tr>
      <th>review_scores_communication</th>
      <td>9.932211</td>
      <td>9.827390</td>
      <td>9.794794</td>
      <td>9.898785</td>
      <td>9.772752</td>
    </tr>
    <tr>
      <th>review_scores_location</th>
      <td>9.644754</td>
      <td>9.548761</td>
      <td>8.904775</td>
      <td>9.596744</td>
      <td>9.412052</td>
    </tr>
    <tr>
      <th>review_scores_value</th>
      <td>9.678822</td>
      <td>9.341224</td>
      <td>9.491638</td>
      <td>9.614187</td>
      <td>9.462490</td>
    </tr>
  </tbody>
</table>
</div>



<p>Although very similar, there are some patterns to be extracted. For example, the East area seems to have lower overall scores.</p>
<h2 id="exercise">Exercise</h2>
<blockquote>
<p><em>Obtain a geodemographic classification with eight classes instead of five and replicate the analysis above</em></p>
<p><em>Re-run the regionalization exercise imposing a minimum of 5% reviews per area</em></p>
</blockquote>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="06_points.html" class="navigation navigation-prev " aria-label="Previous page: Points">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="08_spatial_regression.html" class="navigation navigation-next " aria-label="Next page: Spatial Regression">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Spatial clustering","level":"1.8.2","depth":2,"next":{"title":"Spatial Regression","level":"1.8.3","depth":2,"path":"ipynb_md/08_spatial_regression.md","ref":"ipynb_md/08_spatial_regression.md","articles":[]},"previous":{"title":"Points","level":"1.8.1","depth":2,"path":"ipynb_md/06_points.md","ref":"ipynb_md/06_points.md","articles":[]},"dir":"ltr"},"config":{"plugins":["katex"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Serif","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Geographic Data Science with PySAL and the pydata stack","gitbook":">=3.0.0","description":"Booklet with material for the workshop at Scipy'16"},"file":{"path":"ipynb_md/07_spatial_clustering.md","mtime":"2016-06-26T16:07:55.000Z","type":"markdown"},"gitbook":{"version":"3.1.1","time":"2016-06-26T16:09:58.496Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

